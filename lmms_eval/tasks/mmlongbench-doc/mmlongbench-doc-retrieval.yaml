dataset_path: yubo2333/MMLongBench-Doc
dataset_kwargs:
  token: False
task: "mmlongbench-doc-retrieval"
test_split: train
output_type: generate_until
doc_to_visual: !function utils.mmlongbench_doc_to_visual
doc_to_text: !function utils.mmlongbench_doc_to_text
doc_to_target: !function utils.mmlongbench_doc_to_target_retrieval
generation_kwargs:
  max_new_tokens: 512
  temperature: 0
  do_sample: False
process_results: !function utils.mmlongbench_retrieval_process_results
metric_list:
  - metric: overall
    aggregation: mean
    higher_is_better: True
  - metric: page_main
    aggregation: mean
    higher_is_better: True
  - metric: page_mentioned
    aggregation: mean
    higher_is_better: True
  - metric: evidence_main
    aggregation: mean
    higher_is_better: True
  - metric: evidence_mentioned
    aggregation: mean
    higher_is_better: True
metadata:
  - version: 0.0
lmms_eval_specific_kwargs:
  default:
    pre_prompt: "Read the document and answer this question: "
    post_prompt: "\nPlease make your answer as concise as possible. If the question isn't answerable, just say 'Not answerable'."